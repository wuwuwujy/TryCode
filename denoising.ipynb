{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "\n",
    "import time\n",
    "\n",
    "from skimage.measure import compare_psnr\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "sigma = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Concat(nn.Module):\n",
    "    def __init__(self, dim, skip, deeper):\n",
    "        super(Concat, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.layer1 = skip\n",
    "        self.layer2 = deeper\n",
    "    def forward(self, input):\n",
    "        inputs = []\n",
    "        inputs.append(self.layer1(input))\n",
    "        inputs.append(self.layer2(input))\n",
    "        return torch.cat(inputs, dim=self.dim)\n",
    "\n",
    "def get_name(name):\n",
    "    name[0] +=1\n",
    "    return str(name[0])\n",
    "\n",
    "def skip(c_in, c_out, c_down, c_up, c_skip, k_down, k_up, k_skip, upsample_mode):\n",
    "    model = nn.Sequential()\n",
    "    model_tmp = model\n",
    "    input_depth = c_in\n",
    "    name = [0]\n",
    "    for i in range(len(c_down)):\n",
    "        layer = nn.Sequential()\n",
    "        layer.add_module(get_name(name),nn.Conv2d(input_depth, c_down[i], k_down, 2, padding=int((k_down - 1) / 2)))\n",
    "        layer.add_module(get_name(name),nn.BatchNorm2d(c_down[i]))\n",
    "        layer.add_module(get_name(name),nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        layer.add_module(get_name(name),nn.Conv2d(c_down[i], c_down[i], k_down, 1, padding=int((k_down - 1) / 2)))\n",
    "        layer.add_module(get_name(name),nn.BatchNorm2d(c_down[i]))\n",
    "        layer.add_module(get_name(name),nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        deeper_main = nn.Sequential()\n",
    "        \n",
    "        if i < len(c_down)-1:\n",
    "            layer.add_module(get_name(name),deeper_main)\n",
    "            layer.add_module(get_name(name),nn.Upsample(scale_factor=2, mode=upsample_mode))\n",
    "            if c_skip[i] != 0:\n",
    "                concat_layers = []\n",
    "                concat_layers.append(nn.Conv2d(input_depth, c_skip[i], k_skip, 1, padding=int((k_skip - 1) / 2)))\n",
    "                concat_layers.append(nn.BatchNorm2d(c_skip[i]))\n",
    "                concat_layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "                model_tmp.add_module(get_name(name),Concat(1, nn.Sequential(*concat_layers), layer))\n",
    "            else:\n",
    "                model_tmp.add_module(get_name(name),layer)\n",
    "            model_tmp.add_module(get_name(name),nn.BatchNorm2d(c_skip[i] + c_up[i + 1] ))\n",
    "            model_tmp.add_module(get_name(name),nn.Conv2d(c_skip[i] + c_up[i + 1], c_up[i], k_up, 1, padding=int((k_up - 1) / 2)))\n",
    "            \n",
    "        else:#last layer\n",
    "            layer.add_module(get_name(name),nn.Upsample(scale_factor=2, mode=upsample_mode))\n",
    "            if c_skip[i] != 0:\n",
    "                concat_layers = []\n",
    "                concat_layers.append(nn.Conv2d(input_depth, c_skip[i], k_skip, 1, padding=int((k_skip - 1) / 2)))\n",
    "                concat_layers.append(nn.BatchNorm2d(c_skip[i]))\n",
    "                concat_layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "                model_tmp.add_module(get_name(name),Concat(1, nn.Sequential(*concat_layers), layer))\n",
    "            else:\n",
    "                model_tmp.add_module(get_name(name),layer)\n",
    "            model_tmp.add_module(get_name(name),nn.BatchNorm2d(c_skip[i] +c_down[i]))\n",
    "            model_tmp.add_module(get_name(name),nn.Conv2d(c_skip[i] + c_down[i], c_up[i], k_up, 1, padding=int((k_up - 1) / 2)))\n",
    "\n",
    "        model_tmp.add_module(get_name(name),nn.BatchNorm2d(c_up[i]))\n",
    "        model_tmp.add_module(get_name(name),nn.LeakyReLU(0.2, inplace=True))\n",
    "        model_tmp.add_module(get_name(name),nn.Conv2d(c_up[i], c_up[i], 1, 1))\n",
    "        model_tmp.add_module(get_name(name),nn.BatchNorm2d(c_up[i]))\n",
    "        model_tmp.add_module(get_name(name),nn.LeakyReLU(0.2, inplace=True))\n",
    "        input_depth = c_down[i]\n",
    "        model_tmp = deeper_main\n",
    "\n",
    "    model.add_module(get_name(name),nn.Conv2d(c_up[0], c_out, 1, 1))\n",
    "    model.add_module(get_name(name),nn.Sigmoid())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img_path, f=False):\n",
    "    img = Image.open(fname)\n",
    "    \n",
    "    size = (img.size[0] - img.size[0] % 32, img.size[1] - img.size[1] % 32)\n",
    "\n",
    "    bbox = [\n",
    "            (img.size[0] - size[0])/2, \n",
    "            (img.size[1] - size[1])/2,\n",
    "            (img.size[0] + size[0])/2,\n",
    "            (img.size[1] + size[1])/2,\n",
    "    ]\n",
    "\n",
    "    img = img.crop(bbox)\n",
    "    \n",
    "    img_np = np.array(img)/255\n",
    "    \n",
    "    if len(img_np.shape) == 3:\n",
    "        img_np = img_np.transpose(2,0,1)\n",
    "    else:\n",
    "        img_np = img_np[None, ...]\n",
    "    \n",
    "    if f:\n",
    "        img_noise_np = np.clip((img_np + np.random.normal(scale=sigma, size=img_np.shape)*255.0).astype(np.uint8), 0, 255)\n",
    "#         if img_np.shape[0] == 1:\n",
    "#             img_np = img_np[0]\n",
    "#         else:\n",
    "        img_noise_np = img_noise_np.transpose(1, 2, 0)\n",
    "        plt.figure()\n",
    "        plt.title(\"img_noise_np\")\n",
    "        plt.imshow(img_noise_np)\n",
    "        img_noise = Image.fromarray(img_noise_np)\n",
    "\n",
    "        img_noise_np = img_noise_np.transpose(2,0,1)/255\n",
    "\n",
    "    else:\n",
    "        img_noise = img\n",
    "        img_noise_np = img_np\n",
    "        plt.figure()\n",
    "        plt.title(\"img_noise_np\")\n",
    "        plt.imshow(img_np.transpose(1,2,0))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"img_np\")\n",
    "    plt.imshow(img_np.transpose(1,2,0))\n",
    "    \n",
    "    \n",
    "    return img, img_np, img_noise, img_noise_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/yujiaq3/deep-image-prior/data/denoising/snail.jpg'\n",
    "img, img_np, img_noise, img_noise_np = process_img(img_path)\n",
    "\n",
    "img_path = '/home/yujiaq3/deep-image-prior/data/denoising/F16_GT.png'\n",
    "img, img_np, img_noise, img_noise_np = process_img(img_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg_noise_std = 1/30 # set to 1./20. for sigma=50\n",
    "LR = 0.01\n",
    "\n",
    "exp_weight=0.99\n",
    "psrn_noisy_pre = 0\n",
    "pre_model = None\n",
    "\n",
    "if 'snail.jpg' in img_path:\n",
    "    num_iter = 2400\n",
    "    input_depth = 3\n",
    "\n",
    "    model = skip(input_depth, 3, \n",
    "               c_down = [8, 16, 32, 64, 128],\n",
    "               c_up =   [8, 16, 32, 64, 128],\n",
    "               c_skip =    [0, 0, 0, 4, 4],  \n",
    "               k_up = 3, k_down = 3, \n",
    "               upsample_mode='bilinear', k_skip=1).type(dtype)\n",
    "\n",
    "elif 'F16_GT.png' in img_path:\n",
    "    num_iter = 3000\n",
    "    input_depth = 32 \n",
    "    \n",
    "    model = skip(input_depth, 3, \n",
    "               c_down = [128] * 5,\n",
    "               c_up =   [128] * 5,\n",
    "               c_skip =    [4] * 5,  \n",
    "               k_up = 3, k_down = 3, \n",
    "               upsample_mode='bilinear', k_skip=1).type(dtype)\n",
    "\n",
    "mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "net_input = torch.zeros([1, input_depth,img.size[1], img.size[0]])\n",
    "\n",
    "net_input = net_input.type(dtype)\n",
    "net_input.uniform_() #net_input.normal_()\n",
    "net_input *= 0.1           \n",
    "noise = net_input.detach().clone()\n",
    "net_input_saved = net_input.detach().clone()\n",
    "\n",
    "img_torch = (torch.from_numpy(img_np)[None, :]).type(dtype)\n",
    "\n",
    "params = [x for x in model.parameters()]\n",
    "optimizer = torch.optim.Adam(params, lr=LR)\n",
    "PSNR = []\n",
    "start = time.time()\n",
    "for i in range(num_iter):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "    out = model(net_input)\n",
    "    \n",
    "    out_avg = out.detach()\n",
    "\n",
    "    loss = mse(out, img_torch)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    out = out.detach().cpu().numpy()[0]\n",
    "    out_avg = out_avg.detach().cpu().numpy()[0]\n",
    "    \n",
    "    psrn_noisy = compare_psnr(img_noise_np, out) \n",
    "    psrn_gt    = compare_psnr(img_np, out) \n",
    "    psrn_gt_sm = compare_psnr(img_np, out_avg)\n",
    "\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"Op time: %f\" % (time.time()-start))\n",
    "        print ('Iteration %05d    Loss %f   PSNR_noisy: %f   PSRN_gt: %f PSNR_gt_sm: %f' % (i, loss.item(), psrn_noisy, psrn_gt, psrn_gt_sm), '\\r', end='')\n",
    "        \n",
    "        if len(img_np.shape)<3:\n",
    "            plt.figure()\n",
    "            plt.title(\"out\")\n",
    "            plt.imshow(np.clip(out, 0, 1)[0])\n",
    "            plt.figure()\n",
    "            plt.title(\"out_avg\")\n",
    "            plt.imshow(np.clip(out_avg, 0, 1)[0])\n",
    "        else:\n",
    "            plt.figure()\n",
    "            plt.title(\"out\")\n",
    "            plt.imshow(np.clip(out, 0, 1).transpose(1,2,0))\n",
    "            plt.figure()\n",
    "            plt.title(\"out_avg\")\n",
    "            plt.imshow(np.clip(out_avg, 0, 1).transpose(1,2,0))\n",
    "        plt.show()\n",
    "        \n",
    "        if psrn_noisy_pre - psrn_noisy > 5:\n",
    "            for prev_para, cur_para in zip(pre_model, model.parameters()):\n",
    "                cur_para.data.copy_(prev_para.cuda())\n",
    "            prev_noise = prev_noise\n",
    "        else:\n",
    "            pre_model = []\n",
    "            for para in model.parameters():\n",
    "                pre_model.append(para.detach().cpu())\n",
    "            psrn_noisy_pre = psrn_noisy\n",
    "\n",
    "            \n",
    "print(\"Op time: %f\" % (time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
